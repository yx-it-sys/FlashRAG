model2path:
    e5: intfloat/e5-base-v2
    bge: BAAI/bge-base-en-v1.5
    contriever: facebook/contriever-msmarco
    llama2-7B-chat: meta-llama/Llama-2-7b-chat-hf
    llama2-7B: meta-llama/Llama-2-7b-hf
    llama2-13B: meta-llama/Llama-2-13b-hf
    llama2-13B-chat: meta-llama/Llama-2-13b-chat-hf
    bge-zh: BAAI/bge-large-zh-v1.5
    jina: jinaai/jina-embeddings-v2-base-en
    selfrag-llama2-7B: selfrag/selfrag-llama2-7b
    llama3-8B-instruct: meta-llama/Llama-2-8b-instruct-hf
    phi-3: microsoft/phi-3-mini-4k-instruct
    qwen-14B: Qwen/Qwen1.5-14B-Chat
    gemma-7B: google/gemma-7b
    baichuan2-7B-chat: baichuan-inc/Baichuan2-7B-Chat
    proposition: google/flan-t5-large
    mistral-7B-instruct: mistralai/Mistral-7B-Instruct-v0.3
    bge-m3: BAAI/bge-m3
    glm-4-9b-chat: THUDM/glm-4-9b-chat
    qwen2.5-7B-instruct: Qwen/Qwen2.5-7B-Instruct
    llama3.1-8B-instruct: meta-llama/Llama-3.1-8B-Instruct
    qwen2-vl-2B: Qwen/Qwen2-VL-2B-Instruct
    qwen2.5-vl-7B: Qwen/Qwen2.5-VL-7B-Instruct
    internvl2-2B: OpenGVLab/InternVL2-2B
    internvl2-8B: OpenGVLab/InternVL2-8B
    internvl2.5-8B: OpenGVLab/InternVL2.5-8B
    llava-7B: liuhaotian/llava-v1.6-mistral-7b
    llava-7B-onevision-ov: liuhaotian/llava-onevision-7b-ov
    openai-clip: openai/clip-vit-large-patch14
    openai-clip-336: openai/clip-vit-large-patch14-336
    chinese-clip: OFA-Sys/chinese-clip-vit-large-patch14
    jina-clip-v2: jinaai/jina-clip-v2
model2pooling:
    e5: mean
    bge: cls
    contriever: mean
    jina: mean
    dpr: pooler
    default: pooler
    bge-zh: cls
    bge-m3: cls
method2index:
    e5: null
    bm25: null
    contriever: null
    clip:
        text: path/to/text_index
        image: path/to/image_index
    bge: null
    bge-m3: null
data_dir: data/datasets/
save_dir: result/hotpotqa_2025_11_26_16_32_experiment
gpu_id: '0'
dataset_name: hotpotqa
split:
- validation
- test
- dev
test_sample_num: 100
random_sample: false
seed: 2024
save_intermediate_data: true
save_note: experiment
retrieval_method: e5
retrieval_model_path: intfloat/e5-base-v2
index_path: data/indexes/e5/e5_flat_inner.index
multimodal_index_path_dict: null
faiss_gpu: false
corpus_path: data/indexes/wiki18_100w.jsonl
instruction: null
retrieval_topk: 5
retrieval_batch_size: 256
retrieval_use_fp16: true
retrieval_query_max_length: 128
save_retrieval_cache: false
use_retrieval_cache: false
retrieval_cache_path: null
retrieval_pooling_method: mean
bm25_backend: bm25s
use_sentence_transformer: false
silent_retrieval: true
seismic_query_cut: 10
seismic_heap_factor: 0.8
use_reranker: false
rerank_model_name: e5
rerank_model_path: intfloat/e5-base-v2
rerank_pooling_method: mean
rerank_topk: 5
rerank_max_length: 512
rerank_batch_size: 256
rerank_use_fp16: true
use_multi_retriever: false
multi_retriever_setting:
    merge_method: concat
    topk: 5
    rerank_model_name: null
    rerank_model_path: null
    retriever_list:
    -   retrieval_method: e5
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: intfloat/e5-base-v2
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: false
        retrieval_batch_size: 256
        rerank_model_name: e5
        rerank_model_path: intfloat/e5-base-v2
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
    -   retrieval_method: bm25
        retrieval_topk: 5
        index_path: null
        retrieval_model_path: bm25
        instruction: null
        bm25_backend: bm25s
        use_reranker: false
        corpus_path: null
        use_sentence_transformer: false
        retrieval_pooling_method: mean
        retrieval_use_fp16: true
        retrieval_query_max_length: 128
        faiss_gpu: false
        retrieval_batch_size: 256
        rerank_model_name: e5
        rerank_model_path: intfloat/e5-base-v2
        retrieval_cache_path: null
        save_retrieval_cache: false
        use_retrieval_cache: false
framework: hf
generator_model: Qwen2.5-7B-Instruct
openai_setting:
    api_key: null
    base_url: null
generator_model_path: data/models/Qwen2.5-7B-Instruct
generator_max_input_len: 32768
generator_batch_size: 4
generation_params:
    max_tokens: 200
    do_sample: false
    temperature: 0.0
    top_p: 0.0
use_fid: false
gpu_memory_utilization: 0.85
metrics:
- em
- f1
- acc
metric_setting:
    retrieval_recall_topk: 5
    tokenizer_name: gpt-4
save_metric_score: true
vllm_gpu_memory_utilization: 0.95
omni_vqa_prompt_path: /root/FlashRAG/exps/idea1/prompts/dfa_vqa_prompts.toml
omni_qa_prompt_path: /root/FlashRAG/exps/idea3/prompts/omni_with_plan.toml
dataset_path: data/datasets/hotpotqa
image_path: data/datasets/okvqa/images/val2014
gpu_num: 1
device: cuda
