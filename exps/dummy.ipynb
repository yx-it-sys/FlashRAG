{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d17aed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0e425e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since lmms-lab/OK-VQA couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at /root/autodl-tmp/huggingface/datasets/lmms-lab___ok-vqa/default/0.0.0/c9f858961f4095a9aeef615057b0822cce967096 (last modified on Sat Nov  1 21:43:34 2025).\n"
     ]
    }
   ],
   "source": [
    "num_samples = 1000\n",
    "seed = 42\n",
    "full_dataset = load_dataset(\"lmms-lab/OK-VQA\", split=\"val2014\")\n",
    "full_dataset = full_dataset.shuffle(seed=seed)\n",
    "dummy_subset = full_dataset.select(range(num_samples))\n",
    "images_ouput_dir = \"data/datasets/images/val2014\"\n",
    "annotations_dir = os.path.dirname(\"data/datasets/annotations/okvqa_dummy_1000.jsonl\")\n",
    "\n",
    "os.makedirs(annotations_dir, exist_ok=True)\n",
    "os.makedirs(images_ouput_dir, exist_ok=True)\n",
    "\n",
    "processed_data = []\n",
    "for item in dummy_subset:\n",
    "    clean_item = {\n",
    "        \"id\": item[\"question_id\"],\n",
    "        \"question\": item[\"question\"],\n",
    "        \"image_id\": item[\"question_id\"],\n",
    "        \"golden_answers\": item[\"answers\"]\n",
    "    }\n",
    "    processed_data.append(clean_item)\n",
    "\n",
    "    image_obj = item[\"image\"]\n",
    "    image_filename = f\"{item['question_id']}.jpg\"\n",
    "    save_path = os.path.join(images_ouput_dir, image_filename)\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        try:\n",
    "            image_obj.save(save_path, 'JPEG')\n",
    "        except Exception as e:\n",
    "            tqdm.write(f\"Could not save image {save_path}. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f9371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing jsonl: 100%|██████████| 1000/1000 [00:00<00:00, 73965.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 entries to data/datasets/annotations/okvqa_dummy_1000.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output_filename = \"okvqa_dummy_1000.jsonl\"\n",
    "output_path = os.path.join(annotations_dir, output_filename)\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    for entry in tqdm(processed_data, desc=\"Writing jsonl\"):\n",
    "        if not isinstance(entry, dict):\n",
    "            try:\n",
    "                entry = dict(entry)\n",
    "            except Exception:\n",
    "                continue\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"Saved {len(processed_data)} entries to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667a237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_json_to_jsonl(input_file_path, output_file_path):\n",
    "    \"\"\"\n",
    "    Reads a standard JSON file (expected to be a list of objects) and\n",
    "    writes it to a JSON Lines (.jsonl) file.\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): The path to the input .json file.\n",
    "        output_file_path (str): The path to the output .jsonl file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file_path, 'r', encoding='utf-8') as infile:\n",
    "            # 1. 一次性读取整个JSON文件，它会被解析成一个Python列表\n",
    "            data = json.load(infile)\n",
    "\n",
    "        # 确保输入文件确实是一个列表\n",
    "        if not isinstance(data, list):\n",
    "            print(f\"Error: The input JSON file '{input_file_path}' does not contain a list of objects.\")\n",
    "            return\n",
    "\n",
    "        with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "            # 2. 遍历列表中的每一个对象（字典）\n",
    "            for entry in data:\n",
    "                # 3. 将每个对象转换成一个JSON格式的字符串\n",
    "                json_string = json.dumps(entry, ensure_ascii=False)\n",
    "                \n",
    "                # 4. 将这个字符串写入新文件，并在末尾添加一个换行符\n",
    "                outfile.write(json_string + '\\n')\n",
    "        \n",
    "        print(f\"Successfully converted '{input_file_path}' to '{output_file_path}'.\")\n",
    "        print(f\"Total entries written: {len(data)}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{input_file_path}' was not found.\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file '{input_file_path}' is not a valid JSON file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4fea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted 'data/okvqa_dummy_100/dev.json' to 'data/okvqa_dummy_100/dev.jsonl'.\n",
      "Total entries written: 100\n"
     ]
    }
   ],
   "source": [
    "input_file = \"data/okvqa_dummy_100/dev.json\"\n",
    "output_file = \"data/okvqa_dummy_100/dev.jsonl\"\n",
    "\n",
    "convert_json_to_jsonl(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77c1e46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成！文件 'data/okvqa_dummy_100/test.jsonl' 已成功更新。\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import json\n",
    "input_filename = 'data/okvqa_dummy_100/test.jsonl'\n",
    "# 使用一个临时文件名，处理完成后会用它替换原文件\n",
    "temp_filename = 'output.jsonl.tmp'\n",
    "\n",
    "try:\n",
    "    # 1. 打开原始文件进行读取，同时打开临时文件进行写入\n",
    "    # 使用 'utf-8' 编码以支持中文字符\n",
    "    with open(input_filename, 'r', encoding='utf-8') as infile, \\\n",
    "         open(temp_filename, 'w', encoding='utf-8') as outfile:\n",
    "        \n",
    "        # 2. 逐行读取和处理\n",
    "        for line in infile:\n",
    "            # 去除行尾可能存在的换行符\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue # 如果是空行，则跳过\n",
    "\n",
    "            # 3. 将JSON字符串解析为Python字典\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # 4. 检查'id'字段是否存在，如果存在则添加新的'image_id'字段\n",
    "            if 'id' in data:\n",
    "                data['image_id'] = data['id']\n",
    "            \n",
    "            # 5. 将修改后的字典转换回JSON字符串，并写入临时文件\n",
    "            # ensure_ascii=False 保证中文字符能正常显示而非Unicode编码\n",
    "            # 别忘了在末尾添加换行符，以保持JSONL格式\n",
    "            outfile.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    # 6. 如果整个过程没有出错，用处理好的临时文件替换原始文件\n",
    "    shutil.move(temp_filename, input_filename)\n",
    "    \n",
    "    print(f\"处理完成！文件 '{input_filename}' 已成功更新。\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：找不到文件 '{input_filename}'。请确保文件在正确的路径下。\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"错误：文件 '{input_filename}' 中存在无效的JSON格式。错误信息: {e}\")\n",
    "    # 如果出错，删除可能已创建的临时文件\n",
    "    if os.path.exists(temp_filename):\n",
    "        os.remove(temp_filename)\n",
    "except Exception as e:\n",
    "    print(f\"发生未知错误: {e}\")\n",
    "    # 如果出错，删除可能已创建的临时文件\n",
    "    if os.path.exists(temp_filename):\n",
    "        os.remove(temp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbccefa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
